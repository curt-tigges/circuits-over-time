{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.data_processing import (\n",
    "    load_edge_scores_into_dictionary,\n",
    "    read_json_file,\n",
    "    get_ckpts,\n",
    "    load_metrics,\n",
    "    compute_ged,\n",
    "    compute_weighted_ged,\n",
    "    compute_gtd,\n",
    "    compute_jaccard_similarity_to_reference,\n",
    "    compute_jaccard_similarity,\n",
    "    compute_weighted_jaccard_similarity,\n",
    "    compute_weighted_jaccard_similarity_to_reference,\n",
    "    aggregate_metrics_to_tensors_step_number,\n",
    "    get_ckpts\n",
    ")\n",
    "\n",
    "from utils.visualization import plot_graph_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'ioi'\n",
    "PERFORMANCE_METRIC = 'logit_diff'\n",
    "MODEL_NAME = 'pythia-160m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f'results/graphs/{MODEL_NAME}/{TASK}'\n",
    "df = load_edge_scores_into_dictionary(folder_path)\n",
    "df = df[df['checkpoint'] >= 4000]\n",
    "\n",
    "perf_metrics = torch.load(f'results/backup/{MODEL_NAME}/nmh_backup_metrics.pt')\n",
    "perf_metric_dict = {checkpoint: perf_metrics[checkpoint]['logit_diff'] for checkpoint in perf_metrics.keys()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the total number of edges in the graph at each checkpoint, filtered by in_circuit\n",
    "subgraph_df = df[df['in_circuit'] == True]\n",
    "\n",
    "# Group by checkpoint and sum the number of edges\n",
    "subgraph_df = subgraph_df.groupby('checkpoint').size().reset_index(name='num_edges')\n",
    "\n",
    "subgraph_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph_metric(subgraph_df, 'num_edges', perf_metric_dict, f'Graph Size for {MODEL_NAME}', y_range=1000, x_axis_col='checkpoint', log_x=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_graph_metric(model_df, 'in_circuit', perf_metric_dict, f'Graph Size for {model}', y_range=1000, x_axis_col='checkpoint', log_x=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
