{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89/1711627342.py:5: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_89/1711627342.py:6: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "ipython = get_ipython()\n",
    "ipython.magic(\"load_ext autoreload\")\n",
    "ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ABCMeta' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mneel_plotly\u001b[39;00m \u001b[39mimport\u001b[39;00m imshow \u001b[39mas\u001b[39;00m imshow_n\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvisualization\u001b[39;00m \u001b[39mimport\u001b[39;00m imshow_p, plot_attention_heads, plot_attention\n\u001b[0;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m generate_data_and_caches\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvisualization_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     plot_attention_heads,\n\u001b[1;32m     35\u001b[0m     scatter_attention_and_contribution,\n\u001b[1;32m     36\u001b[0m     get_attn_head_patterns\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n",
      "File \u001b[0;32m~/projects/circuits-over-time/utils/data_utils.py:50\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m _logits_to_mean_logit_diff, _ioi_metric_noising\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgreater_than_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m YearDataset, get_valid_years, get_year_indices\n\u001b[0;32m---> 50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msentiment_datasets\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dataset, PromptType\n\u001b[1;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctools\u001b[39;00m \u001b[39mimport\u001b[39;00m partial\n\u001b[1;32m     54\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TensorType \u001b[39mas\u001b[39;00m TT\n",
      "File \u001b[0;32m~/projects/circuits-over-time/data/sentiment_datasets.py:88\u001b[0m\n\u001b[1;32m     84\u001b[0m         new_words\u001b[39m.\u001b[39mappend(trunc)\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m new_words\n\u001b[0;32m---> 88\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCircularList\u001b[39;00m(UserList[T]):\n\u001b[1;32m     89\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m     90\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(index, \u001b[39mslice\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ABCMeta' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Optional, Union, Dict, Tuple\n",
    "from pathlib import Path \n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import circuitsvis as cv\n",
    "\n",
    "import transformer_lens.utils as tl_utils\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "import transformer_lens.patching as patching\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from torch import Tensor\n",
    "from jaxtyping import Float\n",
    "import plotly.express as px\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from torchtyping import TensorType as TT\n",
    "\n",
    "from path_patching_cm.path_patching import Node, IterNode, path_patch, act_patch\n",
    "from path_patching_cm.ioi_dataset import IOIDataset, NAMES\n",
    "from neel_plotly import imshow as imshow_n\n",
    "\n",
    "from utils.visualization import imshow_p, plot_attention_heads, plot_attention\n",
    "from utils.data_utils import generate_data_and_caches\n",
    "from utils.visualization_utils import (\n",
    "    plot_attention_heads,\n",
    "    scatter_attention_and_contribution,\n",
    "    get_attn_head_patterns\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4d97f075e641ccabc557ff5b07af71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/569 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f403db06d3c046438be5cbba486e1849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/375M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e40d5c40e540a984f43fa9d46cfbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa55aef3c0545b18e34d99833a71029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e27b1bc62a4898a46fff12d24a3b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-160m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"EleutherAI/pythia-160m\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=False,\n",
    ")\n",
    "model.set_use_hook_mlp_in(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_logits(\n",
    "        logits: Float[Tensor, \"batch seq d_vocab\"],\n",
    "        positions: Float[Tensor, \"batch\"] = None\n",
    ")-> Float[Tensor, \"batch d_vocab\"]:\n",
    "    \"\"\"Gets the logits at the provided positions. If no positions are provided, the final logits are returned.\n",
    "\n",
    "    Args:\n",
    "        logits (torch.Tensor): Logits to use.\n",
    "        positions (torch.Tensor): Positions to get logits at. This should be a tensor of shape (batch_size,).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Logits at the provided positions.\n",
    "    \"\"\"\n",
    "    if positions is None:\n",
    "        return logits[:, -1, :]\n",
    "    \n",
    "    return logits[range(logits.size(0)), positions, :]\n",
    "\n",
    "\n",
    "def compute_logit_diff(\n",
    "        logits: Float[Tensor, \"batch seq d_vocab\"], \n",
    "        answer_token_indices: Float[Tensor, \"batch num_answers\"],\n",
    "        positions: Float[Tensor, \"batch\"] = None,\n",
    "        flags_tensor: torch.Tensor = None,\n",
    "        per_prompt=False,\n",
    "        mode=\"simple\"\n",
    ")-> Float[Tensor, \"batch num_answers\"]:\n",
    "    \"\"\"Computes the difference between a correct and incorrect logit (or mean of a group of logits) for each item in the batch.\n",
    "\n",
    "    Takes the full logits, and the indices of the tokens to compare. These indices can be of multiple types as follows:\n",
    "\n",
    "    - Simple: The tensor should be of shape (batch_size, 2), where the first index in the third dimension is the correct token index,\n",
    "        and the second index is the incorrect token index.\n",
    "\n",
    "    - Pairs: In this mode, answer_token_indices is a 3D tensor of shape (batch, num_pairs, 2). For each pair, you'll need to compute \n",
    "             the difference between the logits at the two indices, then average these differences across each pair for every batch item.\n",
    "\n",
    "    - Groups: Here, answer_token_indices is also a 3D tensor of shape (batch, num_tokens, 2). The third dimension indicates group membership \n",
    "              (correct or incorrect). The mean logits for each group are calculated and then subtracted from each other.\n",
    "              \n",
    "\n",
    "    Args:\n",
    "        logits (torch.Tensor): Logits to use.\n",
    "        answer_token_indices (torch.Tensor): Indices of the tokens to compare.\n",
    "        positions (torch.Tensor): Positions to get logits at. Should be one position per batch item.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Difference between the logits of the provided tokens.\n",
    "    \"\"\"\n",
    "    logits = get_positional_logits(logits, positions)\n",
    "    \n",
    "    # Mode 1: Simple\n",
    "    if mode == \"simple\":\n",
    "        correct_logits = logits[torch.arange(logits.size(0)), answer_token_indices[:, 0]]\n",
    "        incorrect_logits = logits[torch.arange(logits.size(0)), answer_token_indices[:, 1]]\n",
    "        logit_diff = correct_logits - incorrect_logits\n",
    "\n",
    "    # Mode 2: Pairs\n",
    "    elif mode == \"pairs\":\n",
    "        pair_diffs = logits[torch.arange(logits.size(0))[:, None], answer_token_indices[..., 0]] - \\\n",
    "                     logits[torch.arange(logits.size(0))[:, None], answer_token_indices[..., 1]]\n",
    "        logit_diff = pair_diffs.mean(dim=1)\n",
    "\n",
    "    # Mode 3: Groups\n",
    "    elif mode == \"groups\":\n",
    "        assert flags_tensor is not None\n",
    "        logit_diff = torch.zeros(logits.size(0), device=logits.device)\n",
    "\n",
    "        for i in range(logits.size(0)):\n",
    "            selected_logits = logits[i, answer_token_indices[i]]\n",
    "\n",
    "            # Calculate the logit difference using the correct/incorrect flags\n",
    "            correct_logits = selected_logits[flags_tensor[i] == 1]\n",
    "            incorrect_logits = selected_logits[flags_tensor[i] == -1]\n",
    "\n",
    "            # Handle cases where there are no correct or incorrect logits\n",
    "            if len(correct_logits) > 0:\n",
    "                correct_mean = correct_logits.mean()\n",
    "            else:\n",
    "                correct_mean = 0\n",
    "\n",
    "            if len(incorrect_logits) > 0:\n",
    "                incorrect_mean = incorrect_logits.mean()\n",
    "            else:\n",
    "                incorrect_mean = 0\n",
    "\n",
    "            logit_diff[i] = correct_mean - incorrect_mean\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode specified\")\n",
    "\n",
    "    return logit_diff.mean() if not per_prompt else logit_diff\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_probability_diff(\n",
    "        logits: torch.Tensor, \n",
    "        answer_token_indices: torch.Tensor,\n",
    "        positions: torch.Tensor = None,\n",
    "        flags_tensor: torch.Tensor = None,\n",
    "        per_prompt=False,\n",
    "        mode=\"simple\"\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Computes the difference between probability of a correct and incorrect logit (or mean of a group of logits) for each item in the batch.\n",
    "\n",
    "    Takes the full logits, and the indices of the tokens to compare. These indices can be of multiple types as follows:\n",
    "\n",
    "    - Simple: The tensor should be of shape (batch_size, 2), where the first index in the third dimension is the correct token index,\n",
    "        and the second index is the incorrect token index.\n",
    "\n",
    "    - Pairs: In this mode, answer_token_indices is a 3D tensor of shape (batch, num_pairs, 2). For each pair, you'll need to compute \n",
    "             the difference between the probabilities at the two indices, then average these differences across each pair for every batch item.\n",
    "\n",
    "    - Groups: Here, answer_token_indices is also a 3D tensor of shape (batch, num_tokens, 2). The third dimension indicates group membership \n",
    "              (correct or incorrect). The mean probabilities for each group are calculated and then subtracted from each other.\n",
    "              \n",
    "\n",
    "    Args:\n",
    "        logits (torch.Tensor): Logits to use.\n",
    "        answer_token_indices (torch.Tensor): Indices of the tokens to compare.\n",
    "        positions (torch.Tensor): Positions to get logits at. Should be one position per batch item.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Difference between the logits of the provided tokens.\n",
    "    \"\"\"\n",
    "    logits = get_positional_logits(logits, positions)\n",
    "    probabilities = torch.softmax(logits, dim=-1)  # Applying softmax to logits\n",
    "    print(f\"probabilities={probabilities.shape}\")\n",
    "\n",
    "    # Mode 1: Simple\n",
    "    if mode == \"simple\":\n",
    "        correct_probs = probabilities[torch.arange(logits.size(0)), answer_token_indices[:, 0]]\n",
    "        incorrect_probs = probabilities[torch.arange(logits.size(0)), answer_token_indices[:, 1]]\n",
    "        prob_diff = correct_probs - incorrect_probs\n",
    "\n",
    "    # Mode 2: Pairs\n",
    "    elif mode == \"pairs\":\n",
    "        pair_diffs = probabilities[torch.arange(logits.size(0))[:, None], answer_token_indices[..., 0]] - \\\n",
    "                     probabilities[torch.arange(logits.size(0))[:, None], answer_token_indices[..., 1]]\n",
    "        prob_diff = pair_diffs.mean(dim=1)\n",
    "\n",
    "    # Mode 3: Groups\n",
    "    elif mode == \"groups\":\n",
    "        # Initialize tensors to store the probability differences for each batch item\n",
    "        assert flags_tensor is not None\n",
    "        prob_diff = torch.zeros(logits.size(0), device=logits.device)\n",
    "\n",
    "        for i in range(logits.size(0)):\n",
    "            # Select the probabilities for the token IDs of this batch item\n",
    "            selected_probs = probabilities[i, answer_token_indices[i]]\n",
    "\n",
    "            # Calculate the probability difference using the correct/incorrect flags\n",
    "            correct_probs = selected_probs[flags_tensor[i] == 1]\n",
    "            incorrect_probs = selected_probs[flags_tensor[i] == -1]\n",
    "\n",
    "            # Handle cases where there are no correct or incorrect tokens\n",
    "            if len(correct_probs) > 0:\n",
    "                correct_mean = correct_probs.mean()\n",
    "            else:\n",
    "                correct_mean = 0\n",
    "\n",
    "            if len(incorrect_probs) > 0:\n",
    "                incorrect_mean = incorrect_probs.mean()\n",
    "            else:\n",
    "                incorrect_mean = 0\n",
    "\n",
    "            prob_diff[i] = correct_mean - incorrect_mean\n",
    "\n",
    "    # Mode 4: Group Sum\n",
    "    elif mode == \"group_sum\":\n",
    "        assert flags_tensor is not None\n",
    "        prob_diff = torch.zeros(logits.size(0), device=logits.device)\n",
    "\n",
    "        for i in range(logits.size(0)):\n",
    "            selected_probs = probabilities[i, answer_token_indices[i]]\n",
    "\n",
    "            # Calculate the sum of probabilities using the correct/incorrect flags\n",
    "            correct_sum = selected_probs[flags_tensor[i] == 1].sum()\n",
    "            incorrect_sum = selected_probs[flags_tensor[i] == -1].sum()\n",
    "\n",
    "            prob_diff[i] = correct_sum - incorrect_sum\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode specified\")\n",
    "\n",
    "    return prob_diff.mean() if not per_prompt else prob_diff\n",
    "\n",
    "\n",
    "def compute_probability_mass(\n",
    "        logits: torch.Tensor, \n",
    "        answer_token_indices: torch.Tensor,\n",
    "        positions: torch.Tensor = None,\n",
    "        flags_tensor: torch.Tensor = None,\n",
    "        group=\"correct\",\n",
    "        mode=\"simple\"\n",
    ") -> torch.Tensor:\n",
    "    logits = get_positional_logits(logits, positions)\n",
    "    probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    # Determine the flag value based on the specified group\n",
    "    flag_value = 1 if group == \"correct\" else -1\n",
    "\n",
    "    # Mode logic\n",
    "    if mode == \"simple\":\n",
    "        selected_indices = answer_token_indices[:, 0] if group == \"correct\" else answer_token_indices[:, 1]\n",
    "        group_probs = probabilities[torch.arange(logits.size(0)), selected_indices]\n",
    "\n",
    "    elif mode == \"pairs\":\n",
    "        group_probs = torch.zeros(logits.size(0), device=logits.device)\n",
    "        for i in range(logits.size(0)):\n",
    "            for pair in answer_token_indices[i]:\n",
    "                selected_index = pair[0] if group == \"correct\" else pair[1]\n",
    "                group_probs[i] += probabilities[i, selected_index]\n",
    "            group_probs[i] /= answer_token_indices.size(1)\n",
    "\n",
    "    elif mode == \"groups\":\n",
    "        assert flags_tensor is not None\n",
    "        group_probs = torch.zeros(logits.size(0), device=logits.device)\n",
    "\n",
    "        for i in range(logits.size(0)):\n",
    "            selected_probs = probabilities[i, answer_token_indices[i]]\n",
    "            group_probs[i] = selected_probs[flags_tensor[i] == flag_value].mean()\n",
    "\n",
    "    elif mode == \"group_sum\":\n",
    "        assert flags_tensor is not None\n",
    "        group_probs = torch.zeros(logits.size(0), device=logits.device)\n",
    "\n",
    "        for i in range(logits.size(0)):\n",
    "            selected_probs = probabilities[i, answer_token_indices[i]]\n",
    "            group_probs[i] = selected_probs[flags_tensor[i] == flag_value].sum()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode specified\")\n",
    "\n",
    "    return group_probs.mean()\n",
    "\n",
    "\n",
    "\n",
    "def compute_rank_0_rate(\n",
    "        logits: torch.Tensor, \n",
    "        answer_token_indices: torch.Tensor,\n",
    "        positions: torch.Tensor = None,\n",
    "        flags_tensor: torch.Tensor = None,\n",
    "        group=\"correct\",\n",
    "        mode=\"simple\"\n",
    ") -> torch.Tensor:\n",
    "    logits = get_positional_logits(logits, positions)\n",
    "    probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    # Mode logic\n",
    "    if mode == \"simple\":\n",
    "        top_rank_indices = probabilities.argmax(dim=-1)\n",
    "        correct_indices = answer_token_indices[:, 0] if group == \"correct\" else answer_token_indices[:, 1]\n",
    "        rank_0_rate = (top_rank_indices == correct_indices).float().mean()\n",
    "\n",
    "    elif mode == \"pairs\":\n",
    "        rank_0_rate = torch.zeros(logits.size(0), device=logits.device)\n",
    "        for i in range(logits.size(0)):\n",
    "            for pair in answer_token_indices[i]:\n",
    "                top_rank_index = probabilities[i].argmax()\n",
    "                correct_index = pair[0] if group == \"correct\" else pair[1]\n",
    "                rank_0_rate[i] += (top_rank_index == correct_index).float()\n",
    "            rank_0_rate[i] /= answer_token_indices.size(1)\n",
    "\n",
    "    elif mode == \"groups\":\n",
    "        assert flags_tensor is not None\n",
    "        rank_0_rate = torch.zeros(logits.size(0), device=logits.device)\n",
    "\n",
    "        for i in range(logits.size(0)):\n",
    "            selected_probs = probabilities[i, answer_token_indices[i]]\n",
    "            top_rank_id = selected_probs.argmax()\n",
    "            rank_0_rate[i] = (flags_tensor[i, top_rank_id] == 1).float() if group == \"correct\" else \\\n",
    "                             (flags_tensor[i, top_rank_id] == -1).float()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode specified\")\n",
    "\n",
    "    return rank_0_rate.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities=torch.Size([1000, 50304])\n"
     ]
    }
   ],
   "source": [
    "logit_diff = compute_logit_diff(logits=clean_logits, answer_token_indices=answer_tokens, flags_tensor=group_flags, mode=\"groups\")\n",
    "probability_diff = compute_probability_diff(logits=clean_logits, answer_token_indices=answer_tokens, flags_tensor=group_flags, mode=\"group_sum\")\n",
    "probability_mass = compute_probability_mass(logits=clean_logits, answer_token_indices=answer_tokens, flags_tensor=group_flags, mode=\"group_sum\", group=\"correct\")\n",
    "rank_0_rate = compute_rank_0_rate(logits=clean_logits, answer_token_indices=answer_tokens, flags_tensor=group_flags, mode=\"groups\", group=\"correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.7268, device='cuda:0'),\n",
       " tensor(0.8294, device='cuda:0'),\n",
       " tensor(0.9136, device='cuda:0'),\n",
       " tensor(0.9960, device='cuda:0'))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_diff, probability_diff, probability_mass, rank_0_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 12, 50304])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_logits.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logits_to_mean_logit_diff(logits: Float[Tensor, \"batch seq d_vocab\"], ioi_dataset: IOIDataset, per_prompt=False):\n",
    "    '''\n",
    "    Returns logit difference between the correct and incorrect answer.\n",
    "\n",
    "    If per_prompt=True, return the array of differences rather than the average.\n",
    "    '''\n",
    "\n",
    "    # Only the final logits are relevant for the answer\n",
    "    # Get the logits corresponding to the indirect object / subject tokens respectively\n",
    "    io_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), ioi_dataset.word_idx[\"end\"], ioi_dataset.io_tokenIDs]\n",
    "    print(io_logits.shape)\n",
    "    s_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), ioi_dataset.word_idx[\"end\"], ioi_dataset.s_tokenIDs]\n",
    "    # Find logit difference\n",
    "    answer_logit_diff = io_logits - s_logits\n",
    "    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average logit diff (IOI dataset): 4.1336\n",
      "Average logit diff (ABC dataset): -4.0758\n"
     ]
    }
   ],
   "source": [
    "N = 70\n",
    "ioi_dataset, abc_dataset, _, _, _ = generate_data_and_caches(model, N, verbose=True)\n",
    "clean_toks = ioi_dataset.toks.to(device)\n",
    "corrupted_toks = abc_dataset.toks.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(clean_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tokens = torch.cat((torch.Tensor(ioi_dataset.io_tokenIDs).unsqueeze(1), torch.Tensor(ioi_dataset.s_tokenIDs).unsqueeze(1)), dim=1).to(device)\n",
    "answer_tokens = answer_tokens.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.3623,  4.5626,  4.4264,  5.5464,  4.9847,  3.3949,  6.6630,  4.6075,\n",
       "         4.1188,  0.7323,  3.5184,  5.4281, -1.2406,  3.1855,  3.9544,  4.9033,\n",
       "         4.9604, -0.5812,  6.0159,  4.4829,  4.9364,  3.5120,  3.6026,  5.8260,\n",
       "         1.5506,  3.6591,  5.1734,  7.8747,  1.9717,  3.0304,  1.3404,  5.6763,\n",
       "         6.4933,  3.3304,  5.4253,  3.1553,  1.6709,  5.3956,  3.8436,  1.4698,\n",
       "         7.1663,  7.1676,  6.1948,  5.9164,  6.3674,  5.1585,  6.8696,  3.2112,\n",
       "         0.9600,  5.3084,  2.2612,  4.1867,  2.8197,  6.8392,  6.7878,  4.9921,\n",
       "         4.7495,  4.8143,  3.2216,  5.5183,  0.8875,  4.1779,  3.3880,  3.5489,\n",
       "         0.9434,  4.0729,  3.7018,  2.4539,  7.2850,  2.4210], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_logit_diff(logits, answer_tokens, ioi_dataset.word_idx[\"end\"].to(device), per_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 3.3623,  4.5626,  4.4264,  5.5464,  4.9847,  3.3949,  6.6630,  4.6075,\n",
       "         4.1188,  0.7323,  3.5184,  5.4281, -1.2406,  3.1855,  3.9544,  4.9033,\n",
       "         4.9604, -0.5812,  6.0159,  4.4829,  4.9364,  3.5120,  3.6026,  5.8260,\n",
       "         1.5506,  3.6591,  5.1734,  7.8747,  1.9717,  3.0304,  1.3404,  5.6763,\n",
       "         6.4933,  3.3304,  5.4253,  3.1553,  1.6709,  5.3956,  3.8436,  1.4698,\n",
       "         7.1663,  7.1676,  6.1948,  5.9164,  6.3674,  5.1585,  6.8696,  3.2112,\n",
       "         0.9600,  5.3084,  2.2612,  4.1867,  2.8197,  6.8392,  6.7878,  4.9921,\n",
       "         4.7495,  4.8143,  3.2216,  5.5183,  0.8875,  4.1779,  3.3880,  3.5489,\n",
       "         0.9434,  4.0729,  3.7018,  2.4539,  7.2850,  2.4210], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_logits_to_mean_logit_diff(logits, ioi_dataset, per_prompt=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greater-Than"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.greater_than_dataset import get_prob_diff, YearDataset, get_valid_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = YearDataset(get_valid_years(model.tokenizer, 1100, 1800), 1000, Path(\"data/potential_nouns.txt\"), model.tokenizer)\n",
    "\n",
    "def batch(iterable, n:int=1):\n",
    "   current_batch = []\n",
    "   for item in iterable:\n",
    "       current_batch.append(item)\n",
    "       if len(current_batch) == n:\n",
    "           yield current_batch\n",
    "           current_batch = []\n",
    "   if current_batch:\n",
    "       yield current_batch\n",
    "\n",
    "clean = list(batch(ds.good_sentences, 9))\n",
    "labels = list(batch(ds.years_YY, 9))\n",
    "corrupted = list(batch(ds.bad_sentences, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 768\n",
    "#model.to_str_tokens(ds.good_toks[IDX]), model.to_str_tokens(ds.bad_toks[IDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def prepare_indices_for_prob_diff(tokenizer, years):\n",
    "    \"\"\"\n",
    "    Prepares two tensors for use with the compute_probability_diff function in 'groups' mode.\n",
    "\n",
    "    Args:\n",
    "        tokenizer (PreTrainedTokenizer): Tokenizer to convert years to token indices.\n",
    "        years (torch.Tensor): Tensor containing the year for each prompt in the batch.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor, torch.Tensor: Two tensors, one for token IDs and one for correct/incorrect flags.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the indices for years 00 to 99\n",
    "    year_indices = get_year_indices(tokenizer)  # Tensor of size 100 with token IDs for years\n",
    "\n",
    "    # Prepare tensors to store token IDs and correct/incorrect flags\n",
    "    token_ids_tensor = year_indices.repeat(years.size(0), 1)  # Repeat the year_indices for each batch item\n",
    "    flags_tensor = torch.zeros_like(token_ids_tensor)  # Initialize the flags tensor with zeros\n",
    "\n",
    "    for i, year in enumerate(years):\n",
    "        # Mark years greater than the given year as correct (1)\n",
    "        flags_tensor[i, year + 1:] = 1\n",
    "        # Mark years less than or equal to the given year as incorrect (-1)\n",
    "        flags_tensor[i, :year + 1] = -1\n",
    "\n",
    "    return token_ids_tensor, flags_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mHookedTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfold_ln\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcenter_writing_weights\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcenter_unembed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrefactor_factored_attn_matrices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcheckpoint_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcheckpoint_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhf_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_auto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_devices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtokenizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPreTrainedTokenizerBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmove_to_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfold_value_biases\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdefault_prepend_bos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdefault_padding_side\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mfrom_pretrained_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'HookedTransformer'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Load in a Pretrained Model.\n",
      "\n",
      "Load in pretrained model weights to the HookedTransformer format and optionally to do some\n",
      "processing to make the model easier to interpret. Currently supports loading from most\n",
      "autoregressive HuggingFace models (``gpt2``, ``neo``, ``gptj``, ``opt``...) and from a range\n",
      "of toy models and SoLU models trained by Neel Nanda. The full list is available in the docs\n",
      "under :doc:`model properties</generated/model_properties_table>`. Also supports loading from\n",
      "a checkpoint for checkpointed models (currently, models trained by NeelNanda and the\n",
      "stanford-crfm models (using parameters ``checkpoint_index`` and ``checkpoint_value``).\n",
      "\n",
      "See :meth:`load_and_process_state_dict` for details on the processing (folding layer norm,\n",
      "centering the unembedding and centering the writing weights).\n",
      "\n",
      "Example:\n",
      "\n",
      ">>> from transformer_lens import HookedTransformer\n",
      ">>> model = HookedTransformer.from_pretrained(\"tiny-stories-1M\")\n",
      "Loaded pretrained model tiny-stories-1M into HookedTransformer\n",
      "\n",
      "Args:\n",
      "    model_name: The model name - must be an element of\n",
      "        :const:`transformer_lens.loading_from_pretrained.OFFICIAL_MODEL_NAMES` or an alias\n",
      "        of one. The full list of available models can be found in the docs under :doc:`model\n",
      "        properties</generated/model_properties_table>`.\n",
      "    fold_ln: Whether to fold in the LayerNorm weights to the\n",
      "        subsequent linear layer. This does not change the computation.\n",
      "\n",
      "        `LayerNorm\n",
      "        <https://wandb.ai/wandb_fc/LayerNorm/reports/Layer-Normalization-in-Pytorch-With-Examples---VmlldzoxMjk5MTk1>`_\n",
      "        is a common regularization technique used in transformers. Unlike BatchNorm, it\n",
      "        cannot be turned off at inference time, as it significantly alters the mathematical\n",
      "        function implemented by the transformer.\n",
      "\n",
      "        When `fold_ln` is set to True, LayerNorm (with weights :math:`w_{ln}` and\n",
      "        :math:`b_{ln}`) followed by a linear layer (:math:`W + b`) is optimized to\n",
      "        LayerNormPre (just centering & normalizing) followed by a new linear layer with\n",
      "        :math:`W_{eff} = w[:,   ext{None}] * W` (element-wise multiplication) and\n",
      "        :math:`b_{eff} = b + b_{ln} @ W`. This transformation is computationally equivalent\n",
      "        and simplifies the model's interpretability. It essentially merges LayerNorm weights\n",
      "        into the subsequent linear layer's weights, which is handled by HookedTransformer\n",
      "        when loading pre-trained weights. Set `fold_ln` to False when loading a state dict\n",
      "        if you wish to turn this off.\n",
      "\n",
      "        Mathematically, LayerNorm is defined as follows:\n",
      "\n",
      "        .. math::\n",
      "            x_1 &= x_0 - \\text{mean}(x_0)\n",
      "\n",
      "            x_2 &= \\frac{x_1}{\\sqrt{\\text{mean}(x_1^2)}}\n",
      "\n",
      "            x_3 &= x_2 \\cdot w\n",
      "\n",
      "            x_4 &= x_3 + b\n",
      "\n",
      "        For further details, refer to `this document\n",
      "        <https://transformer-circuits.pub/2021/framework/index.html#:~:text=Handling%20Layer%20Normalization>`_.\n",
      "    center_writing_weights: Whether to center weights\n",
      "        writing to the residual stream (ie set mean to be zero). Due to LayerNorm this\n",
      "        doesn't change the computation.\n",
      "\n",
      "        A related idea to folding layernorm (``fold_ln``) - *every* component reading an\n",
      "        input from the residual stream is preceded by a LayerNorm, which means that the mean\n",
      "        of a residual stream vector (ie the component in the direction of all ones) never\n",
      "        matters. This means we can remove the all ones component of weights and biases whose\n",
      "        output *writes* to the residual stream. Mathematically, ``W_writing -=\n",
      "        W_writing.mean(dim=1, keepdim=True)``.\n",
      "    center_unembed: Whether to center W_U (ie set mean\n",
      "        to be zero). Softmax is translation invariant so this doesn't affect log probs or\n",
      "        loss, but does change logits.\n",
      "\n",
      "        The logits are fed into a softmax. Softmax is translation invariant (eg, adding 1 to\n",
      "        every logit doesn't change the output), so we can simplify things by setting the\n",
      "        mean of the logits to be zero. This is equivalent to setting the mean of every\n",
      "        output vector of ``W_U`` to zero. In code, ``W_U -= W_U.mean(dim=-1,\n",
      "        keepdim=True)``.\n",
      "    refactor_factored_attn_matrices: Whether to convert the factored\n",
      "        matrices (W_Q & W_K, and W_O & W_V) to be \"even\". Defaults to False\n",
      "    checkpoint_index: If loading from a checkpoint, the index of\n",
      "        the checkpoint to load.\n",
      "    checkpoint_value: If loading from a checkpoint, the value of\n",
      "        the checkpoint to load, ie the step or token number (each model has checkpoints\n",
      "        labelled with exactly one of these). E.g. ``1000`` for a checkpoint taken at step\n",
      "        1000 or after 1000 tokens. If `checkpoint_index` is also specified, this will be\n",
      "        ignored.\n",
      "    hf_model: If you have already loaded in the\n",
      "        HuggingFace model, you can pass it in here rather than needing to recreate the\n",
      "        object. Defaults to None.\n",
      "    device: The device to load the model onto. By\n",
      "        default will load to CUDA if available, else CPU.\n",
      "    n_devices: The number of devices to split the model\n",
      "        across. Defaults to 1. If greater than 1, `device` must be cuda.\n",
      "    tokenizer: The tokenizer to use for the model. If not\n",
      "        provided, it is inferred from cfg.tokenizer_name or initialized to None. If None,\n",
      "        then the model cannot be passed strings, and d_vocab must be explicitly set.\n",
      "    move_to_device: Whether to move the model to the device specified in\n",
      "        cfg. device. Must be true if `n_devices` in the config is greater than 1, since the\n",
      "        model's layers will be split across multiple devices.\n",
      "    fold_value_biases: Each attention head has a value bias. Values are averaged to create\n",
      "        mixed values (``z``), weighted by the attention pattern, but as the bias is\n",
      "        constant, its contribution to ``z`` is exactly the same. The output of a head is ``z\n",
      "        @ W_O``, and so the value bias just linearly adds to the output of the head. This\n",
      "        means that the value bias of a head has nothing to do with the head, and is just a\n",
      "        constant added to the attention layer outputs. We can take the sum across these and\n",
      "        b_O to get an \"effective bias\" for the layer. In code, we set ``b_V=0``. and ``b_O =\n",
      "        (b_V @ W_O).sum(dim=0) + b_O``.\n",
      "\n",
      "        The technical derivation of this is as follows. ``v = residual @ W_V[h] +\n",
      "        broadcast_b_V[h]`` for each head ``h`` (where ``b_V`` is broadcast up from shape\n",
      "        ``d_head`` to shape ``[position, d_head]``). And ``z = pattern[h] @ v = pattern[h] @\n",
      "        residual @ W_V[h] + pattern[h] @ broadcast_b_V[h]``. Because ``pattern[h]`` is\n",
      "        ``[destination_position, source_position]`` and ``broadcast_b_V`` is constant along\n",
      "        the ``(source_)position`` dimension, we're basically just multiplying it by the sum\n",
      "        of the pattern across the ``source_position`` dimension, which is just ``1``. So it\n",
      "        remains exactly the same, and so is just broadcast across the destination positions.\n",
      "    default_prepend_bos: Default behavior of whether to prepend the BOS\n",
      "        token when the methods of HookedTransformer process input text to tokenize (only\n",
      "        when input is a string). Defaults to True - even for models not explicitly trained\n",
      "        with this, heads often use the first position as a resting position and accordingly\n",
      "        lose information from the first token, so this empirically seems to give better\n",
      "        results. To change the default behavior to False, pass in default_prepend_bos=False.\n",
      "        Note that you can also locally override the default behavior by passing in\n",
      "        prepend_bos=True/False when you call a method that processes the input string.\n",
      "    from_pretrained_kwargs: Any other optional argument passed to\n",
      "        HuggingFace's from_pretrained (e.g. \"cache_dir\" or \"torch_dtype\"). Also passed to\n",
      "        other HuggingFace functions when compatible. For some models or arguments it doesn't\n",
      "        work, especially for models that are not internally loaded with HuggingFace's\n",
      "        from_pretrained (e.g. SoLU models).\n",
      "    dtype: What data type to load the model in (also sets the dtype of\n",
      "        the HuggingFace model). Set to bfloat16 or float16 if you get out of memory errors when loading\n",
      "        the model.\n",
      "    default_padding_side: Which side to pad on when tokenizing. Defaults to\n",
      "        \"right\".\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfold_ln\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcenter_writing_weights\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcenter_unembed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrefactor_factored_attn_matrices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcheckpoint_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcheckpoint_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mhf_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mn_devices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtokenizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPreTrainedTokenizerBase\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmove_to_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfold_value_biases\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdefault_prepend_bos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdefault_padding_side\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"right\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"right\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mfrom_pretrained_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"HookedTransformer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Load in a Pretrained Model.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Load in pretrained model weights to the HookedTransformer format and optionally to do some\u001b[0m\n",
      "\u001b[0;34m        processing to make the model easier to interpret. Currently supports loading from most\u001b[0m\n",
      "\u001b[0;34m        autoregressive HuggingFace models (``gpt2``, ``neo``, ``gptj``, ``opt``...) and from a range\u001b[0m\n",
      "\u001b[0;34m        of toy models and SoLU models trained by Neel Nanda. The full list is available in the docs\u001b[0m\n",
      "\u001b[0;34m        under :doc:`model properties</generated/model_properties_table>`. Also supports loading from\u001b[0m\n",
      "\u001b[0;34m        a checkpoint for checkpointed models (currently, models trained by NeelNanda and the\u001b[0m\n",
      "\u001b[0;34m        stanford-crfm models (using parameters ``checkpoint_index`` and ``checkpoint_value``).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        See :meth:`load_and_process_state_dict` for details on the processing (folding layer norm,\u001b[0m\n",
      "\u001b[0;34m        centering the unembedding and centering the writing weights).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        >>> from transformer_lens import HookedTransformer\u001b[0m\n",
      "\u001b[0;34m        >>> model = HookedTransformer.from_pretrained(\"tiny-stories-1M\")\u001b[0m\n",
      "\u001b[0;34m        Loaded pretrained model tiny-stories-1M into HookedTransformer\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Args:\u001b[0m\n",
      "\u001b[0;34m            model_name: The model name - must be an element of\u001b[0m\n",
      "\u001b[0;34m                :const:`transformer_lens.loading_from_pretrained.OFFICIAL_MODEL_NAMES` or an alias\u001b[0m\n",
      "\u001b[0;34m                of one. The full list of available models can be found in the docs under :doc:`model\u001b[0m\n",
      "\u001b[0;34m                properties</generated/model_properties_table>`.\u001b[0m\n",
      "\u001b[0;34m            fold_ln: Whether to fold in the LayerNorm weights to the\u001b[0m\n",
      "\u001b[0;34m                subsequent linear layer. This does not change the computation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                `LayerNorm\u001b[0m\n",
      "\u001b[0;34m                <https://wandb.ai/wandb_fc/LayerNorm/reports/Layer-Normalization-in-Pytorch-With-Examples---VmlldzoxMjk5MTk1>`_\u001b[0m\n",
      "\u001b[0;34m                is a common regularization technique used in transformers. Unlike BatchNorm, it\u001b[0m\n",
      "\u001b[0;34m                cannot be turned off at inference time, as it significantly alters the mathematical\u001b[0m\n",
      "\u001b[0;34m                function implemented by the transformer.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                When `fold_ln` is set to True, LayerNorm (with weights :math:`w_{ln}` and\u001b[0m\n",
      "\u001b[0;34m                :math:`b_{ln}`) followed by a linear layer (:math:`W + b`) is optimized to\u001b[0m\n",
      "\u001b[0;34m                LayerNormPre (just centering & normalizing) followed by a new linear layer with\u001b[0m\n",
      "\u001b[0;34m                :math:`W_{eff} = w[:, \\text{None}] * W` (element-wise multiplication) and\u001b[0m\n",
      "\u001b[0;34m                :math:`b_{eff} = b + b_{ln} @ W`. This transformation is computationally equivalent\u001b[0m\n",
      "\u001b[0;34m                and simplifies the model's interpretability. It essentially merges LayerNorm weights\u001b[0m\n",
      "\u001b[0;34m                into the subsequent linear layer's weights, which is handled by HookedTransformer\u001b[0m\n",
      "\u001b[0;34m                when loading pre-trained weights. Set `fold_ln` to False when loading a state dict\u001b[0m\n",
      "\u001b[0;34m                if you wish to turn this off.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                Mathematically, LayerNorm is defined as follows:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                .. math::\u001b[0m\n",
      "\u001b[0;34m                    x_1 &= x_0 - \\\\text{mean}(x_0)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                    x_2 &= \\\\frac{x_1}{\\\\sqrt{\\\\text{mean}(x_1^2)}}\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                    x_3 &= x_2 \\\\cdot w\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                    x_4 &= x_3 + b\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                For further details, refer to `this document\u001b[0m\n",
      "\u001b[0;34m                <https://transformer-circuits.pub/2021/framework/index.html#:~:text=Handling%20Layer%20Normalization>`_.\u001b[0m\n",
      "\u001b[0;34m            center_writing_weights: Whether to center weights\u001b[0m\n",
      "\u001b[0;34m                writing to the residual stream (ie set mean to be zero). Due to LayerNorm this\u001b[0m\n",
      "\u001b[0;34m                doesn't change the computation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                A related idea to folding layernorm (``fold_ln``) - *every* component reading an\u001b[0m\n",
      "\u001b[0;34m                input from the residual stream is preceded by a LayerNorm, which means that the mean\u001b[0m\n",
      "\u001b[0;34m                of a residual stream vector (ie the component in the direction of all ones) never\u001b[0m\n",
      "\u001b[0;34m                matters. This means we can remove the all ones component of weights and biases whose\u001b[0m\n",
      "\u001b[0;34m                output *writes* to the residual stream. Mathematically, ``W_writing -=\u001b[0m\n",
      "\u001b[0;34m                W_writing.mean(dim=1, keepdim=True)``.\u001b[0m\n",
      "\u001b[0;34m            center_unembed: Whether to center W_U (ie set mean\u001b[0m\n",
      "\u001b[0;34m                to be zero). Softmax is translation invariant so this doesn't affect log probs or\u001b[0m\n",
      "\u001b[0;34m                loss, but does change logits.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                The logits are fed into a softmax. Softmax is translation invariant (eg, adding 1 to\u001b[0m\n",
      "\u001b[0;34m                every logit doesn't change the output), so we can simplify things by setting the\u001b[0m\n",
      "\u001b[0;34m                mean of the logits to be zero. This is equivalent to setting the mean of every\u001b[0m\n",
      "\u001b[0;34m                output vector of ``W_U`` to zero. In code, ``W_U -= W_U.mean(dim=-1,\u001b[0m\n",
      "\u001b[0;34m                keepdim=True)``.\u001b[0m\n",
      "\u001b[0;34m            refactor_factored_attn_matrices: Whether to convert the factored\u001b[0m\n",
      "\u001b[0;34m                matrices (W_Q & W_K, and W_O & W_V) to be \"even\". Defaults to False\u001b[0m\n",
      "\u001b[0;34m            checkpoint_index: If loading from a checkpoint, the index of\u001b[0m\n",
      "\u001b[0;34m                the checkpoint to load.\u001b[0m\n",
      "\u001b[0;34m            checkpoint_value: If loading from a checkpoint, the value of\u001b[0m\n",
      "\u001b[0;34m                the checkpoint to load, ie the step or token number (each model has checkpoints\u001b[0m\n",
      "\u001b[0;34m                labelled with exactly one of these). E.g. ``1000`` for a checkpoint taken at step\u001b[0m\n",
      "\u001b[0;34m                1000 or after 1000 tokens. If `checkpoint_index` is also specified, this will be\u001b[0m\n",
      "\u001b[0;34m                ignored.\u001b[0m\n",
      "\u001b[0;34m            hf_model: If you have already loaded in the\u001b[0m\n",
      "\u001b[0;34m                HuggingFace model, you can pass it in here rather than needing to recreate the\u001b[0m\n",
      "\u001b[0;34m                object. Defaults to None.\u001b[0m\n",
      "\u001b[0;34m            device: The device to load the model onto. By\u001b[0m\n",
      "\u001b[0;34m                default will load to CUDA if available, else CPU.\u001b[0m\n",
      "\u001b[0;34m            n_devices: The number of devices to split the model\u001b[0m\n",
      "\u001b[0;34m                across. Defaults to 1. If greater than 1, `device` must be cuda.\u001b[0m\n",
      "\u001b[0;34m            tokenizer: The tokenizer to use for the model. If not\u001b[0m\n",
      "\u001b[0;34m                provided, it is inferred from cfg.tokenizer_name or initialized to None. If None,\u001b[0m\n",
      "\u001b[0;34m                then the model cannot be passed strings, and d_vocab must be explicitly set.\u001b[0m\n",
      "\u001b[0;34m            move_to_device: Whether to move the model to the device specified in\u001b[0m\n",
      "\u001b[0;34m                cfg. device. Must be true if `n_devices` in the config is greater than 1, since the\u001b[0m\n",
      "\u001b[0;34m                model's layers will be split across multiple devices.\u001b[0m\n",
      "\u001b[0;34m            fold_value_biases: Each attention head has a value bias. Values are averaged to create\u001b[0m\n",
      "\u001b[0;34m                mixed values (``z``), weighted by the attention pattern, but as the bias is\u001b[0m\n",
      "\u001b[0;34m                constant, its contribution to ``z`` is exactly the same. The output of a head is ``z\u001b[0m\n",
      "\u001b[0;34m                @ W_O``, and so the value bias just linearly adds to the output of the head. This\u001b[0m\n",
      "\u001b[0;34m                means that the value bias of a head has nothing to do with the head, and is just a\u001b[0m\n",
      "\u001b[0;34m                constant added to the attention layer outputs. We can take the sum across these and\u001b[0m\n",
      "\u001b[0;34m                b_O to get an \"effective bias\" for the layer. In code, we set ``b_V=0``. and ``b_O =\u001b[0m\n",
      "\u001b[0;34m                (b_V @ W_O).sum(dim=0) + b_O``.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                The technical derivation of this is as follows. ``v = residual @ W_V[h] +\u001b[0m\n",
      "\u001b[0;34m                broadcast_b_V[h]`` for each head ``h`` (where ``b_V`` is broadcast up from shape\u001b[0m\n",
      "\u001b[0;34m                ``d_head`` to shape ``[position, d_head]``). And ``z = pattern[h] @ v = pattern[h] @\u001b[0m\n",
      "\u001b[0;34m                residual @ W_V[h] + pattern[h] @ broadcast_b_V[h]``. Because ``pattern[h]`` is\u001b[0m\n",
      "\u001b[0;34m                ``[destination_position, source_position]`` and ``broadcast_b_V`` is constant along\u001b[0m\n",
      "\u001b[0;34m                the ``(source_)position`` dimension, we're basically just multiplying it by the sum\u001b[0m\n",
      "\u001b[0;34m                of the pattern across the ``source_position`` dimension, which is just ``1``. So it\u001b[0m\n",
      "\u001b[0;34m                remains exactly the same, and so is just broadcast across the destination positions.\u001b[0m\n",
      "\u001b[0;34m            default_prepend_bos: Default behavior of whether to prepend the BOS\u001b[0m\n",
      "\u001b[0;34m                token when the methods of HookedTransformer process input text to tokenize (only\u001b[0m\n",
      "\u001b[0;34m                when input is a string). Defaults to True - even for models not explicitly trained\u001b[0m\n",
      "\u001b[0;34m                with this, heads often use the first position as a resting position and accordingly\u001b[0m\n",
      "\u001b[0;34m                lose information from the first token, so this empirically seems to give better\u001b[0m\n",
      "\u001b[0;34m                results. To change the default behavior to False, pass in default_prepend_bos=False.\u001b[0m\n",
      "\u001b[0;34m                Note that you can also locally override the default behavior by passing in\u001b[0m\n",
      "\u001b[0;34m                prepend_bos=True/False when you call a method that processes the input string.\u001b[0m\n",
      "\u001b[0;34m            from_pretrained_kwargs: Any other optional argument passed to\u001b[0m\n",
      "\u001b[0;34m                HuggingFace's from_pretrained (e.g. \"cache_dir\" or \"torch_dtype\"). Also passed to\u001b[0m\n",
      "\u001b[0;34m                other HuggingFace functions when compatible. For some models or arguments it doesn't\u001b[0m\n",
      "\u001b[0;34m                work, especially for models that are not internally loaded with HuggingFace's\u001b[0m\n",
      "\u001b[0;34m                from_pretrained (e.g. SoLU models).\u001b[0m\n",
      "\u001b[0;34m            dtype: What data type to load the model in (also sets the dtype of\u001b[0m\n",
      "\u001b[0;34m                the HuggingFace model). Set to bfloat16 or float16 if you get out of memory errors when loading\u001b[0m\n",
      "\u001b[0;34m                the model.\u001b[0m\n",
      "\u001b[0;34m            default_padding_side: Which side to pad on when tokenizing. Defaults to\u001b[0m\n",
      "\u001b[0;34m                \"right\".\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mfrom_pretrained_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"load_in_8bit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mor\u001b[0m \u001b[0mfrom_pretrained_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"load_in_4bit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Quantization not supported\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Convert from string to a torch dtype\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDTYPE_FROM_STRING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"torch_dtype\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrom_pretrained_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# For backwards compatibility with the previous way to do low precision loading\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# This should maybe check the user did not explicitly set dtype *and* torch_dtype\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_pretrained_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"torch_dtype\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m(\u001b[0m\u001b[0mfrom_pretrained_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch_dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"float16 models may not work on CPU. Consider using a GPU or bfloat16.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Get the model name used in HuggingFace, rather than the alias.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mofficial_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_official_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Load the config into an HookedTransformerConfig object. If loading from a\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# checkpoint, the config object will contain the information about the\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# checkpoint\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pretrained_model_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mofficial_model_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcheckpoint_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcheckpoint_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mfold_ln\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold_ln\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mn_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdefault_prepend_bos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_prepend_bos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m**\u001b[0m\u001b[0mfrom_pretrained_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"shortformer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mfold_ln\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"You tried to specify fold_ln=True for a shortformer model, but this can't be done! Setting fold_\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"ln=False instead.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mfold_ln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mcenter_unembed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"You tried to specify center_unembed=True for a shortformer model, but this can't be done! \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Setting center_unembed=False instead.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mcenter_unembed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mcenter_writing_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"You tried to specify center_writing_weights=True for a shortformer model, but this can't be done! \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Setting center_writing_weights=False instead.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mcenter_writing_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Get the state dict of the model (ie a mapping of parameter names to tensors), processed to\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# match the HookedTransformer parameter names.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pretrained_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mofficial_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfrom_pretrained_kwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Create the HookedTransformer object\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmove_to_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdefault_padding_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_padding_side\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_process_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mfold_ln\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold_ln\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcenter_writing_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcenter_writing_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcenter_unembed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcenter_unembed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mfold_value_biases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold_value_biases\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mrefactor_factored_attn_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefactor_factored_attn_matrices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmove_to_device\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_model_modules_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded pretrained model {model_name} into HookedTransformer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/circuits/lib/python3.8/site-packages/transformer_lens/HookedTransformer.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "HookedTransformer.from_pretrained??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_length = 1 + len(model.tokenizer(ds.good_sentences[0])[0])\n",
    "prob_diff = get_prob_diff(model.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.circuit_utils import run_with_batches\n",
    "\n",
    "clean_logits = run_with_batches(model, ds.good_toks.to(device), batch_size=20, max_seq_len=12)\n",
    "corrupted_logits = run_with_batches(model, ds.bad_toks.to(device), batch_size=20, max_seq_len=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tokens, group_flags = prepare_indices_for_prob_diff(model.tokenizer, torch.Tensor(ds.years_YY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 12, 50304]), torch.Size([1000, 100, 2]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_logits.shape, answer_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8294, device='cuda:0')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_diff(clean_logits,ds.years_YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff = compute_logit_diff(logits=clean_logits, answer_token_indices=answer_tokens, flags_tensor=group_flags, mode=\"groups\")\n",
    "probability_diff = compute_probability_diff(logits=clean_logits, answer_token_indices=answer_tokens, flags_tensor=group_flags, mode=\"group_sum\")\n",
    "probability_mass = compute_probability_mass(logits=clean_logits, answer_token_indices=answer_tokens, flags_tensor=group_flags, mode=\"groups\", group=\"correct\")\n",
    "rank_0_rate = compute_rank_0_rate(logits=clean_logits, answer_token_indices=answer_tokens, flags_tensor=group_flags, mode=\"groups\", group=\"correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_cache/pythia-160m/step143000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-160m into HookedTransformer\n",
      "Clean logit diff: -0.8333\n",
      "Corrupted logit diff: 0.2896\n",
      "Moving model to device:  cpu\n",
      "Loading model for step 1...\n",
      "model_cache/pythia-160m/step1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-160m into HookedTransformer\n",
      "Getting metric values...\n",
      "Moving model to device:  cpu\n",
      "Loading model for step 2...\n",
      "model_cache/pythia-160m/step2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-160m into HookedTransformer\n",
      "Getting metric values...\n"
     ]
    }
   ],
   "source": [
    "from utils.model_utils import clear_gpu_memory, load_model\n",
    "from utils.circuit_utils import CircuitMetric\n",
    "import utils.circuit_utils as cu\n",
    "\n",
    "model_name = \"pythia-160m\"\n",
    "model_full_name = \"EleutherAI/pythia-160m\"\n",
    "model_tl_full_name = \"EleutherAI/pythia-160m\"\n",
    "cache_dir = \"model_cache\"\n",
    "batch_size = 20\n",
    "\n",
    "\n",
    "model = load_model(\n",
    "    model_full_name, model_tl_full_name, \"step143000\", cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "# set up data\n",
    "ds = YearDataset(get_valid_years(model.tokenizer, 1100, 1800), 100, Path(\"data/potential_nouns.txt\"), model.tokenizer)\n",
    "\n",
    "prob_diff = get_prob_diff(model.tokenizer)\n",
    "prob_diff_metric = CircuitMetric(\"prob_diff\", partial(prob_diff, years=ds.years_YY))\n",
    "\n",
    "metrics = [prob_diff_metric]\n",
    "\n",
    "# get baselines\n",
    "clean_logits = cu.run_with_batches(model, ds.good_toks.to(device), batch_size=20, max_seq_len=12)\n",
    "corrupted_logits = cu.run_with_batches(model, ds.bad_toks.to(device), batch_size=20, max_seq_len=12)\n",
    "\n",
    "clean_prob_diff = prob_diff_metric(clean_logits)\n",
    "print(f\"Clean logit diff: {clean_prob_diff:.4f}\")\n",
    "\n",
    "corrupted_prob_diff = prob_diff_metric(corrupted_logits)\n",
    "print(f\"Corrupted logit diff: {corrupted_prob_diff:.4f}\")\n",
    "\n",
    "clear_gpu_memory(model)\n",
    "\n",
    "# specify checkpoint schedule\n",
    "\n",
    "ckpts = [1, 2]\n",
    "\n",
    "# get values over time\n",
    "results_dict = cu.get_chronological_circuit_performance_flexible(\n",
    "    model_full_name,\n",
    "    model_tl_full_name,\n",
    "    cache_dir,\n",
    "    ckpts,\n",
    "    clean_tokens=ds.good_toks.to(device),\n",
    "    corrupted_tokens=ds.bad_toks.to(device),\n",
    "    metrics=metrics,\n",
    "    max_seq_len=12,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# save results\n",
    "os.makedirs(f\"results/{model_name}-no-dropout\", exist_ok=True)\n",
    "\n",
    "for metric in results_dict.keys():\n",
    "    torch.save(\n",
    "        results_dict[metric], f\"results/{model_name}-no-dropout/{metric}.pt\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.sentiment_datasets import get_dataset, PromptType, get_prompts\n",
    "from utils.circuit_analysis import get_logit_diff as get_logit_diff_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_type = PromptType.CLASSIFICATION_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading prompts from config and filtering\n"
     ]
    }
   ],
   "source": [
    "prompts = get_prompts(model, ds_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I thought this movie was amazing, I loved it. The acting was awesome, the plot was beautiful, and overall the movie was just very good. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' amazing', ',', ' I', ' loved', ' it', '.', ' The', ' acting', ' was', ' awesome', ',', ' the', ' plot', ' was', ' beautiful', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' good', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was awesome, I loved it. The acting was beautiful, the plot was brilliant, and overall the movie was just very good. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' awesome', ',', ' I', ' loved', ' it', '.', ' The', ' acting', ' was', ' beautiful', ',', ' the', ' plot', ' was', ' brilliant', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' good', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was beautiful, I loved it. The acting was brilliant, the plot was exceptional, and overall the movie was just very good. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' beautiful', ',', ' I', ' loved', ' it', '.', ' The', ' acting', ' was', ' brilliant', ',', ' the', ' plot', ' was', ' exceptional', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' good', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was brilliant, I loved it. The acting was exceptional, the plot was extraordinary, and overall the movie was just very good. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' brilliant', ',', ' I', ' loved', ' it', '.', ' The', ' acting', ' was', ' exceptional', ',', ' the', ' plot', ' was', ' extraordinary', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' good', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was exceptional, I loved it. The acting was extraordinary, the plot was fabulous, and overall the movie was just very good. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' exceptional', ',', ' I', ' loved', ' it', '.', ' The', ' acting', ' was', ' extraordinary', ',', ' the', ' plot', ' was', ' fabulous', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' good', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was extraordinary, I loved it. The acting was fabulous, the plot was fantastic, and overall the movie was just very good. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' extraordinary', ',', ' I', ' loved', ' it', '.', ' The', ' acting', ' was', ' fabulous', ',', ' the', ' plot', ' was', ' fantastic', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' good', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was fabulous, I loved it. The acting was fantastic, the plot was good, and overall the movie was just very good. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' fabulous', ',', ' I', ' loved', ' it', '.', ' The', ' acting', ' was', ' fantastic', ',', ' the', ' plot', ' was', ' good', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' good', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was fantastic, I loved it. The acting was good, the plot was great, and overall the movie was just very good. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' fantastic', ',', ' I', ' loved', ' it', '.', ' The', ' acting', ' was', ' good', ',', ' the', ' plot', ' was', ' great', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' good', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was good, I loved it. The acting was great, the plot was incredible, and overall the movie was just very good. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' good', ',', ' I', ' loved', ' it', '.', ' The', ' acting', ' was', ' great', ',', ' the', ' plot', ' was', ' incredible', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' good', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was great, I loved it. The acting was incredible, the plot was lovely, and overall the movie was just very good. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' great', ',', ' I', ' loved', ' it', '.', ' The', ' acting', ' was', ' incredible', ',', ' the', ' plot', ' was', ' lovely', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' good', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was incredible, I loved it. The acting was lovely, the plot was outstanding, and overall the movie was just very good. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' incredible', ',', ' I', ' loved', ' it', '.', ' The', ' acting', ' was', ' lovely', ',', ' the', ' plot', ' was', ' outstanding', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' good', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was awful, I hated it. The acting was bad, the plot was disappointing, and overall the movie was just very applaud. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' awful', ',', ' I', ' hated', ' it', '.', ' The', ' acting', ' was', ' bad', ',', ' the', ' plot', ' was', ' disappointing', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' applaud', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was bad, I hated it. The acting was disappointing, the plot was disgusting, and overall the movie was just very appreciate. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' bad', ',', ' I', ' hated', ' it', '.', ' The', ' acting', ' was', ' disappointing', ',', ' the', ' plot', ' was', ' disgusting', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' appreciate', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was disappointing, I hated it. The acting was disgusting, the plot was dreadful, and overall the movie was just very commend. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' disappointing', ',', ' I', ' hated', ' it', '.', ' The', ' acting', ' was', ' disgusting', ',', ' the', ' plot', ' was', ' dreadful', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' commend', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was disgusting, I hated it. The acting was dreadful, the plot was horrible, and overall the movie was just very embrace. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' disgusting', ',', ' I', ' hated', ' it', '.', ' The', ' acting', ' was', ' dreadful', ',', ' the', ' plot', ' was', ' horrible', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' embrace', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was dreadful, I hated it. The acting was horrible, the plot was miserable, and overall the movie was just very endorse. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' dreadful', ',', ' I', ' hated', ' it', '.', ' The', ' acting', ' was', ' horrible', ',', ' the', ' plot', ' was', ' miserable', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' endorse', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was horrible, I hated it. The acting was miserable, the plot was offensive, and overall the movie was just very enjoy. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' horrible', ',', ' I', ' hated', ' it', '.', ' The', ' acting', ' was', ' miserable', ',', ' the', ' plot', ' was', ' offensive', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' enjoy', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was miserable, I hated it. The acting was offensive, the plot was terrible, and overall the movie was just very favor. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' miserable', ',', ' I', ' hated', ' it', '.', ' The', ' acting', ' was', ' offensive', ',', ' the', ' plot', ' was', ' terrible', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' favor', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was offensive, I hated it. The acting was terrible, the plot was unpleasant, and overall the movie was just very like. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' offensive', ',', ' I', ' hated', ' it', '.', ' The', ' acting', ' was', ' terrible', ',', ' the', ' plot', ' was', ' unpleasant', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' like', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was terrible, I hated it. The acting was unpleasant, the plot was wretched, and overall the movie was just very love. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' terrible', ',', ' I', ' hated', ' it', '.', ' The', ' acting', ' was', ' unpleasant', ',', ' the', ' plot', ' was', ' wretched', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' love', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was unpleasant, I hated it. The acting was wretched, the plot was awful, and overall the movie was just very praise. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' unpleasant', ',', ' I', ' hated', ' it', '.', ' The', ' acting', ' was', ' wretched', ',', ' the', ' plot', ' was', ' awful', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' praise', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n",
      "I thought this movie was wretched, I hated it. The acting was awful, the plot was bad, and overall the movie was just very respect. Review Sentiment:\n",
      "['<|endoftext|>', 'I', ' thought', ' this', ' movie', ' was', ' wretched', ',', ' I', ' hated', ' it', '.', ' The', ' acting', ' was', ' awful', ',', ' the', ' plot', ' was', ' bad', ',', ' and', ' overall', ' the', ' movie', ' was', ' just', ' very', ' respect', '.', ' Review', ' Sent', 'iment', ':']\n",
      "torch.Size([1, 35])\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts[0][\"positive\"]:\n",
    "    print(prompt)\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    print(model.to_str_tokens(tokens))\n",
    "    print(tokens.shape)\n",
    "\n",
    "for prompt in prompts[0][\"negative\"]:\n",
    "    print(prompt)\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    print(model.to_str_tokens(tokens))\n",
    "    print(tokens.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,    42,  1869,   436,  6440,   369,  8644,    13,   309,  7636,\n",
       "           352,    15,   380,  8534,   369, 13103,    13,   253,  7484,   369,\n",
       "          5389,    13,   285,  4583,   253,  6440,   369,   816,  1077,  1175,\n",
       "            15,  8439, 20580,  2092,    27]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_tokens(prompts[0][\"positive\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'positive': ['I thought this movie was amazing, I loved it. The acting was awesome, the plot was beautiful, and overall the movie was just very good. Review Sentiment:',\n",
       "   'I thought this movie was awesome, I loved it. The acting was beautiful, the plot was brilliant, and overall the movie was just very good. Review Sentiment:',\n",
       "   'I thought this movie was beautiful, I loved it. The acting was brilliant, the plot was exceptional, and overall the movie was just very good. Review Sentiment:',\n",
       "   'I thought this movie was brilliant, I loved it. The acting was exceptional, the plot was extraordinary, and overall the movie was just very good. Review Sentiment:',\n",
       "   'I thought this movie was exceptional, I loved it. The acting was extraordinary, the plot was fabulous, and overall the movie was just very good. Review Sentiment:',\n",
       "   'I thought this movie was extraordinary, I loved it. The acting was fabulous, the plot was fantastic, and overall the movie was just very good. Review Sentiment:',\n",
       "   'I thought this movie was fabulous, I loved it. The acting was fantastic, the plot was good, and overall the movie was just very good. Review Sentiment:',\n",
       "   'I thought this movie was fantastic, I loved it. The acting was good, the plot was great, and overall the movie was just very good. Review Sentiment:',\n",
       "   'I thought this movie was good, I loved it. The acting was great, the plot was incredible, and overall the movie was just very good. Review Sentiment:',\n",
       "   'I thought this movie was great, I loved it. The acting was incredible, the plot was lovely, and overall the movie was just very good. Review Sentiment:',\n",
       "   'I thought this movie was incredible, I loved it. The acting was lovely, the plot was outstanding, and overall the movie was just very good. Review Sentiment:'],\n",
       "  'negative': ['I thought this movie was awful, I hated it. The acting was bad, the plot was disappointing, and overall the movie was just very applaud. Review Sentiment:',\n",
       "   'I thought this movie was bad, I hated it. The acting was disappointing, the plot was disgusting, and overall the movie was just very appreciate. Review Sentiment:',\n",
       "   'I thought this movie was disappointing, I hated it. The acting was disgusting, the plot was dreadful, and overall the movie was just very commend. Review Sentiment:',\n",
       "   'I thought this movie was disgusting, I hated it. The acting was dreadful, the plot was horrible, and overall the movie was just very embrace. Review Sentiment:',\n",
       "   'I thought this movie was dreadful, I hated it. The acting was horrible, the plot was miserable, and overall the movie was just very endorse. Review Sentiment:',\n",
       "   'I thought this movie was horrible, I hated it. The acting was miserable, the plot was offensive, and overall the movie was just very enjoy. Review Sentiment:',\n",
       "   'I thought this movie was miserable, I hated it. The acting was offensive, the plot was terrible, and overall the movie was just very favor. Review Sentiment:',\n",
       "   'I thought this movie was offensive, I hated it. The acting was terrible, the plot was unpleasant, and overall the movie was just very like. Review Sentiment:',\n",
       "   'I thought this movie was terrible, I hated it. The acting was unpleasant, the plot was wretched, and overall the movie was just very love. Review Sentiment:',\n",
       "   'I thought this movie was unpleasant, I hated it. The acting was wretched, the plot was awful, and overall the movie was just very praise. Review Sentiment:',\n",
       "   'I thought this movie was wretched, I hated it. The acting was awful, the plot was bad, and overall the movie was just very respect. Review Sentiment:'],\n",
       "  'neutral': ['I thought this movie was ok, I watched it. The acting was okay, the plot was OK, and overall the movie was just very average. Review Sentiment:',\n",
       "   'I thought this movie was okay, I watched it. The acting was OK, the plot was alright, and overall the movie was just very average. Review Sentiment:',\n",
       "   'I thought this movie was OK, I watched it. The acting was alright, the plot was fine, and overall the movie was just very average. Review Sentiment:',\n",
       "   'I thought this movie was alright, I watched it. The acting was fine, the plot was neutral, and overall the movie was just very average. Review Sentiment:',\n",
       "   'I thought this movie was fine, I watched it. The acting was neutral, the plot was acceptable, and overall the movie was just very average. Review Sentiment:',\n",
       "   'I thought this movie was neutral, I watched it. The acting was acceptable, the plot was fair, and overall the movie was just very average. Review Sentiment:',\n",
       "   'I thought this movie was acceptable, I watched it. The acting was fair, the plot was standard, and overall the movie was just very average. Review Sentiment:',\n",
       "   'I thought this movie was fair, I watched it. The acting was standard, the plot was reasonable, and overall the movie was just very average. Review Sentiment:',\n",
       "   'I thought this movie was standard, I watched it. The acting was reasonable, the plot was average, and overall the movie was just very average. Review Sentiment:',\n",
       "   'I thought this movie was reasonable, I watched it. The acting was average, the plot was ok, and overall the movie was just very average. Review Sentiment:',\n",
       "   'I thought this movie was average, I watched it. The acting was ok, the plot was okay, and overall the movie was just very average. Review Sentiment:']},\n",
       " {'positive': CircularList([' Positive']),\n",
       "  'negative': CircularList([' Negative'])})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading prompts from config and filtering\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I thought this movie was amazing, I loved it. The acting was awesome, the plot was beautiful, and overall the movie was just very good. Review Sentiment:'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = get_dataset(model, device, prompt_type=ds_type)\n",
    "ds.all_prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 35])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.clean_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 1, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.answer_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logits = model(ds.clean_tokens.to(device))\n",
    "corrupted_logits = model(ds.corrupted_tokens.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 1, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.answer_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import CircuitMetric\n",
    "logit_diff_metric = CircuitMetric(\"logit_diff_multi\", partial(get_logit_diff_ca, answer_tokens=ds.answer_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3842, device='cuda:0'), tensor(-0.3842, device='cuda:0'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_diff_metric(clean_logits), logit_diff_metric(corrupted_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3842, device='cuda:0'), tensor(-0.3842, device='cuda:0'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_logit_diff(clean_logits, ds.answer_tokens, mode=\"pairs\"), compute_logit_diff(corrupted_logits, ds.answer_tokens, mode=\"pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
